% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\KOMAoption{captions}{tableheading}
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={MATH/STAT 455: Mathematical Statistics},
  pdfauthor={Taylor Okonek},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{MATH/STAT 455: Mathematical Statistics}
\author{Taylor Okonek}
\date{2023-12-07}

\begin{document}
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[boxrule=0pt, breakable, sharp corners, borderline west={3pt}{0pt}{shadecolor}, interior hidden, frame hidden, enhanced]}{\end{tcolorbox}}\fi

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\bookmarksetup{startatroot}

\hypertarget{welcome-to-mathematical-statistics}{%
\chapter*{Welcome to Mathematical
Statistics!}\label{welcome-to-mathematical-statistics}}
\addcontentsline{toc}{chapter}{Welcome to Mathematical Statistics!}

\markboth{Welcome to Mathematical Statistics!}{Welcome to Mathematical
Statistics!}

This book contains the course notes for \emph{MATH/STAT 455:}
\emph{Mathematical Statistics} at Macalester College, as taught by
Prof.~\href{https://taylorokonek.github.io/}{Taylor Okonek}. These notes
draw from course notes created by
Prof.~\href{https://kegrinde.github.io/}{Kelsey Grinde}, and heavily
from the course textbook, \emph{An Introduction to Mathematical
Statistics and Its Applications} by Richard Larsen and Morris Marx (6th
Edition). Each chapter will contain (at a minimum):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Learning Objectives
\item
  Reading Guide
\item
  Definitions
\item
  Theorems
\item
  Worked Examples
\end{enumerate}

\textbf{I will be editing and adding to these notes throughout Spring
2024, so please check consistently for updates!}

If you find any typos or have other questions, please email
\href{mailto:tokonek@macalester.edu}{\nolinkurl{tokonek@macalester.edu}}.

\begin{verbatim}
\end{verbatim}

\bookmarksetup{startatroot}

\hypertarget{probability-a-brief-review}{%
\chapter{Probability: A Brief Review}\label{probability-a-brief-review}}

\emph{MATH/STAT 455} builds directly on topics covered in
\emph{MATH/STAT 354: Probability}. You're not expected to perfectly
remember everything from \emph{Probability}, but you will need to have
sufficient facility with the following topics covered in this review
Chapter in order to grasp the majority of concepts covered in
\emph{MATH/STAT 455}.

\hypertarget{learning-objectives}{%
\section{Learning Objectives}\label{learning-objectives}}

By the end of this chapter, you should be able to\ldots{}

\begin{itemize}
\item
  Distinguish between important probability models (e.g., Normal,
  Binomial)
\item
  Derive the expectation and variance of a single random variable or a
  sum of random variables
\item
  Define the moment generating function and use it to find moments or
  identify pdfs
\end{itemize}

\hypertarget{reading-guide}{%
\section{Reading Guide}\label{reading-guide}}

Associated Readings: Chapters 2-4 (pages 15-277)

\hypertarget{reading-questions}{%
\subsection{Reading Questions}\label{reading-questions}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Which probability distributions are appropriate for
  \emph{quantitative} (continuous) random variables?
\item
  Which probability distributions are appropriate for \emph{categorical}
  random variables?
\item
  \emph{Independently and Identically Distributed (iid)} random
  variables are an incredibly important assumption involved in many
  statistical methods. Why do you think it might be important/useful for
  random variables to have this property?
\end{enumerate}

\hypertarget{definitions}{%
\section{Definitions}\label{definitions}}

You are expected to know the following definitions:

\textbf{Random Variable}

A random variable is a function that takes inputs from a sample space of
all possible outcomes, and outputs real values or probabilities. As an
example, consider a coin flip. The sample space of all possible outcomes
consists of ``heads'' and ``tails'', and each outcome is associated with
a probability (50\% each, for a fair coin). For our purposes, you should
know that random variables have probability density (or mass) functions,
and are either discrete or continuous based on the number of possible
outcomes a random variable may take. Random variables are often denoted
with capital Roman letters, like \(X\), \(Y\), \(Z\), etc.

\textbf{Probability density function} (discrete, continuous)

\begin{itemize}
\tightlist
\item
  Note: I don't care if you call a pmf a pdf\ldots{} I will probably do
  this continuously throughout the semester. We don't need to be picky
  about this in \emph{MATH/STAT 455}.
\end{itemize}

There are many different accepted ways to write the notation for a pdf
of a random variables. Any of the following are perfectly appropriate
for this class: \(f(x)\), \(\pi(x)\), \(p(x)\), \(f_X(x)\). I typically
use either \(\pi\) or \(p\), but might mix it up occasionally.

Key things I want you to know about probability density functions:

\begin{itemize}
\item
  \(\pi(x) \geq 0\), everywhere. This should make sense (hopefully)
  because probabilities cannot be negative!
\item
  \(\int_{-\infty}^\infty \pi(x) = 1\). This should also (hopefully)
  makes sense. Probabilities can't be \emph{greater} than one, and the
  probability of event occurring \emph{at all (ever)} should be equal to
  one, if the event \(x\) is a random variable.
\end{itemize}

\textbf{Cumulative distribution function} (discrete, continuous)

Cumulative distribution functions we'll typically write as \(F_X(x)\).
or \(F(x)\), for short. It is important to know that

\[
F_X(x) = \Pr(X \leq x),
\]

or in words, ``the cumulative distribution function is the probability
that a random variable lies before \(x\).'' If you write \(\Pr(X < x)\)
instead of \(\leq\), you're fine. The probability that a random variable
is exactly one number (for an RV with a continuous pdf) is zero anyway,
so these are the same thing. Key things I want you to know about
cumulative distribution functions:

\begin{itemize}
\item
  \(F(x)\) is non-decreasing. This is in part where the ``cumulative''
  piece comes in to play. Recall that probabilities are basically
  integrals or sums. If we're integrating over something positive, and
  our upper bound for our integral \emph{increases}, the area under the
  curve (cumulative probability) will increase as well.
\item
  \(0 \leq F(x) \leq 1\) (since probabilities have to be between zero
  and one!)
\item
  \(\Pr(a < X \leq b) = F(a) - F(b)\) (because algebra)
\end{itemize}

\textbf{Joint probability density function}

A joint probability density function is a probability distribution
defined for more than one random variable at a time. For two random
variables, \(X\) and \(Z\), we could write their joint density function
as \(f_{X,Z}(x, z)\) , or \(f(x,z)\) for short. The joint density
function encodes all sorts of fun information, including \emph{marginal}
distributions for \(X\) and \(Z\), and conditional distributions (see
next \textbf{bold} definition). We can think of the joint pdf as listing
all possible pairs of outputs from the density function \(f(x,z)\), for
varying values of \(x\) and \(z\). Key things I want you to know about
joint pdfs:

\begin{itemize}
\item
  How to get a marginal pdf from a joint pdf:

  Suppose I want to know \(f_X(x)\), and I know \(f_{X,Z}(x,z)\). Then I
  can integrate or ``average over'' \(Z\) to get

  \[
  f_X(x) = \int f_{X,Z}(x,z)dz
  \]
\item
  The relationship between conditional pdfs, marginal pdfs, joint pdfs,
  and Bayes' theorem/rule
\item
  How to obtain a joint pdf for \emph{independent} random variables:
  just multiply their marginal pdfs together! This is how we will
  (typically) think about likelihoods!
\item
  How to obtain a marginal pdf from a joint pdf when random variables
  are independent \emph{without integrating} (think, ``separability'')
\end{itemize}

\textbf{Conditional probability density function}

A conditional pdf denotes the probability distribution for a (set of)
random variable(s), \emph{given that} the value for another (set of)
random variable(s) is known. For two random variables, \(X\) and \(Z\),
we could write the conditional distribution of \(X\) ``given'' \(Z\) as
\(f_{X \mid Z}(x \mid z)\) , where the ``conditioning'' is denoted by a
vertical bar (in LaTeX, this is typeset using ``\textbackslash mid'').
Key things I want you to know about conditional pdfs:

\begin{itemize}
\item
  The relationship between conditional pdfs, marginal pdfs, joint pdfs,
  and Bayes' theorem/rule
\item
  How to obtain a conditional pdf from a joint pdf (again, think Bayes'
  rule)
\item
  Relationship between conditional pdfs and independence (see next
  \textbf{bold} definition)
\end{itemize}

\textbf{Independence}

Two random variables \(X\) and \(Z\) are \emph{independent} if and only
if:

\begin{itemize}
\item
  \(f_{X,Z}(x,z) = f_X(x) f_Z(z)\) (their joint pdf is ``separable'')
\item
  \(f_{X\mid Z}(x\mid z) = f_X(x)\) (the pdf for \(X\) does not depend
  on \(Z\) in any way)

  Note that the ``opposite'' is also true:
  \(f_{Z\mid X}(z\mid x) = f_Z(z)\)
\end{itemize}

In notation, we denote that two variables are independent as
\(X \perp\!\!\!\perp Z\), or \(X \perp Z\). In LaTeX, the \emph{latter}
is typeset as ``\textbackslash perp'', and the former is typeset as
``\textbackslash perp\textbackslash!\textbackslash!\textbackslash!\textbackslash perp''.
As a matter of personal preference, I (Taylor) prefer
\(\perp\!\!\!\perp\), but I don't like typing it out every time.
Consider using the ``\textbackslash newcommand'' functionality in LaTeX
to create a shorthand for this for your documents!

\textbf{Expected Value / Expectation}

The expectation (or expected value) of a random variable is defined as:

\[
E[X] = \int_{-\infty}^\infty x f(x) dx
\]

Expected value is a weighted average, where the average is over all
possible values a random variable can take, weighted by the probability
that those values occur. Key things I want you to know about
expectation:

\begin{itemize}
\item
  The relationship between expectation, variance, and moments
  (specifically, that \(E[X]\) is the 1st moment!)
\item
  The ``law of the unconscious statistician'' (see the Theorems section
  of this chapter)
\item
  Expectation of linear transformations of random variables (see
  \textbf{Theorems} section of this chapter)
\end{itemize}

\textbf{Variance}

The variance of a random variable is defined as:

\[
Var[X] = E[(X - E[X])^2] = E[X^2] - E[X]^2
\]

In words, we can read this as ``the expected value of the squared
deviation from the mean'' of a random variable \(X\). Key things I want
you to know about variance:

\begin{itemize}
\item
  The relationship between expectation, variance, and moments (hopefully
  clear, given the formula for variance)
\item
  The relationship between variance and standard deviation:
  \(Var(X) = sd(X)^2\)
\item
  The relationship between variance and covariance:
  \(Var(X) = Cov(X, X)\)
\item
  \(Var(X) \geq 0\). This should make sense, given that we're taking the
  expectation of something ``squared'' in order to calculate it!
\item
  \(Var(c) = 0\) for any constant, \(c\).
\item
  Variance of linear transformations of random variables (see
  \textbf{Theorems} section of this chapter)
\end{itemize}

\(r^{th}\) \textbf{moment}

The \(r^{th}\) moment of a probability distribution is given by
\(E[X^r]\). For example, when \(r = 1\), the \(r^{th}\) moment is just
the expectation of the random variable \(X\). Key things I want you to
know about moments:

\begin{itemize}
\item
  The relationship between moments, expectation, and variance

  \begin{itemize}
  \tightlist
  \item
    For example, if you know the first and second moments of a
    distribution, you should be able to calculate the variance of a
    random variable with that distribution!
  \end{itemize}
\item
  The relationship between moments and \emph{moment generating
  functions} (see \textbf{Theorems} section of this chapter)
\end{itemize}

\textbf{Covariance}

The covariance of two random variables is a measure of their
\emph{joint} variability. We denote the covariance of two random
variables \(X\) and \(Z\) as \(Cov(X,Z)\), and

\[
Cov(X, Z) = E[(X - E[X])(Y - E[Y])] = E[XY] - E[X]E[Y]
\]

Some things I want you to know about covariance:

\begin{itemize}
\item
  \(Cov(X, X) = Var(X)\)
\item
  \(Cov(X, Y) = Cov(Y, X)\) (order doesn't matter)
\end{itemize}

\textbf{Moment Generating Function (MGF)}

The moment generating function of a random variable \(X\) is defined as

\[
M_X(t) = E[e^{tX}]
\]

A few things to note:

\begin{itemize}
\item
  \(M_X(0) = 1\), always.
\item
  If two random variables have the same MGF, they have the same
  probability distribution!
\item
  MGFs are sometimes useful for showing how different random variables
  are related to each other
\end{itemize}

You are also expected to know the probability distributions contained in
Table 1, below. Note that you \emph{do not} need to memorize the pdfs
for these distributions, but you \emph{should} be familiar with what
types of random variables (continuous/quantitative, categorical,
integer-valued, etc.) may take on different distributions. The more
familiar you are with the forms of the pdfs, the easier/faster it will
be to work through problem sets and quizzes.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.4444}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3056}}@{}}
\caption{\emph{Table 1.} Table of main probability distributions we will
work with for \emph{MATH/STAT 455}.}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Distribution
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
PDF/PMF
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Parameters
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Distribution
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
PDF/PMF
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Parameters
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Uniform & \(\pi(x) = \frac{1}{\beta - \alpha}\) &
\(\alpha \in \mathbb{R}\), \(\beta\in \mathbb{R}\) \\
Normal &
\(\pi(x) = \frac{1}{\sqrt{2\pi \sigma^2}} \exp(-\frac{1}{2\sigma^2} (x - \mu)^2)\)
& \(\mu \in \mathbb{R}\), \(\sigma > 0\) \\
Multivariate Normal &
\(\pi(\textbf{x}) = (2\pi)^{-k/2} |\Sigma|^{-1/2} \exp(-\frac{1}{2}(\textbf{x} - \mu)^\top \Sigma^{-1}(\textbf{x} - \mu)))\)
& \(\mu \in \mathbb{R}^k\), \(\Sigma \in \mathbb{R}^{k\times k}\) ,
positive semi-definite (in practice, almost always positive definite) \\
Gamma &
\(\pi(x) = \frac{\beta^{\alpha}}{\Gamma(\alpha)}x^{\alpha - 1} e^{-\beta x}\)
& \(\alpha \text{ (shape)}, \beta \text{ (rate)} > 0\) \\
Chi-square &
\(\pi(x) = \frac{2^{-\nu/2}}{\Gamma(\nu/2)} x^{\nu/2 - 1}e^{-x/2})\) &
\(\nu > 0\) \\
Exponential & \(\pi(x) = \beta e^{-\beta x}\) & \(\beta > 0\) \\
Student-\$t\$ &
\(\pi(x) = \frac{\Gamma((\nu + 1)/2)}{\Gamma(\nu/2) \sqrt{\nu \pi}} (1 + \frac{x^2}{\nu})^{-(\nu + 1)/2}\)
& \(\nu > 0\) \\
Beta &
\(\pi(x) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} x^{\alpha - 1}(1 - x)^{\beta - 1}\)
& \(\alpha, \beta > 0\) \\
Poisson & \(\pi(x) = \frac{\lambda^k e^{-\lambda}}{k!}\) &
\(\lambda > 0\) \\
Binomial & \(\pi(x) = \binom{n}{x} p^{x} (1 - p)^{n - x}\) &
\(p \in [0,1], n = \{0, 1, 2, \dots\}\) \\
Multinomial &
\(\pi(\textbf{x}) = \frac{n!}{x_1! \dots x_k!} p_1^{x_1} \dots p_k^{x_k}\)
& \(p_i > 0\), \(p_1 + \dots + p_k = 1\), \(n = \{0, 1, 2, \dots \}\) \\
Negative Binomial & \(\pi(x) = \binom{k + r - 1}{k} (1-p)^k p^r\) &
\(r > 0\), \(p \in [0,1]\) \\
\end{longtable}

\hypertarget{theorems}{%
\section{Theorems}\label{theorems}}

\begin{itemize}
\item
  Law of Total Probability

  \[
  P(A) = \sum_n P(A \cap B_n),
  \]or

  \[
  P(A) = \sum_n P(A \mid B_n) P(B_n)
  \]
\item
  Bayes' Theorem

  \[
  \pi(A \mid B) = \frac{\pi(B \mid A) \pi(A)}{\pi(B)}
  \]
\item
  Relationship between pdf and cdf

  \[
  F_Y(y) = \int_{-\infty}^y f_Y(t)dt
  \]

  \[
  \frac{\partial}{\partial y}F_Y(y) = f_Y(y)
  \]
\item
  Expectation of random variables

  \[
  E[X] = \int_{-\infty}^\infty x f(x) dx
  \]

  \[
  E[X^2] = \int_{-\infty}^\infty x^2 f(x) dx
  \]

  \begin{itemize}
  \item
    ``Law of the Unconscious Statistician''

    \[
    E[g(X)] = \int_{-\infty}^\infty g(x)f(x)dx
    \]
  \end{itemize}
\item
  Expectation and variance of linear transformations of random variables

  \[
  E[cX + b] = c E[X] + b
  \]

  \[
  Var[cX + b] = c^2 Var[X]
  \]
\item
  Relationship between mean and variance

  \[
  Var[X] = E[(X - E[X])^2] = E[X^2] - E[X]^2
  \]

  Also, recall that \(Cov[X, X] = Var[X]\).
\item
  Finding a marginal pdf from a joint pdf

  \[
  f_X(x) = \int_{-\infty}^\infty f_{X,Y}(x, y) dy
  \]
\item
  Independence of random variables and joint pdfs

  If two random variables are independent, their joint pdf will be
  \emph{separable}. For example, if \(X\) and \(Y\) are independent, we
  could write

  \[
  f_{X,Y}(x, y) = f_{X}(x)f_Y(y)
  \]
\item
  Expected value of a product of independent random variables

  Suppose random variables \(X_1, \dots, X_n\) are independent. Then we
  can write,

  \[
  E\left[\prod_{i = 1}^n X_i\right] = \prod_{i = 1}^n E[X_i]
  \]
\item
  Covariance of independent random variables

  If \(X\) and \(Y\) are independent, then \(Cov(X, Y) = 0\). We can
  show this by noting that
\end{itemize}

\[
\begin{align}
Cov(X, Y) & = E[(X - E[X])(Y - E[Y])] \\
& = E[XY - XE[Y] - YE[X] + E[X]E[Y]] \\
& = E[XY] - E[XE[Y]] - E[YE[X]] + E[X]E[Y] \\
& =  2E[X]E[Y] - 2E[X]E[Y] \\
& = 0
\end{align}
\]

\begin{itemize}
\item
  Using MGFs to find moments

  Recall that the moment generating function of a random variable \(X\),
  denoted by \(M_X(t)\) is

  \[
  M_X(t) = E[e^{tX}]
  \]

  Then the \(n\)th moment of the probability distribution for \(X\) ,
  \(E[X^n]\), is given by

  \[
  \frac{\partial M_X}{\partial t^n} \Bigg|_{t = 0} 
  \]

  where the above reads as ``the \(n\)th derivative of the moment
  generating function, evaluated at \(t = 0\).''
\item
  Using MGFs to identify pdfs

  MGFs uniquely identify probability density functions. If \(X\) and
  \(Y\) are two random variables where for all values of \(t\),
  \(M_X(t) = M_Y(t)\), then \(F_X(x) = F_Y(y)\).
\item
  Central Limit Theorem

  The classical CLT states that for independent and identically
  distributed (iid) random variables \(X_1, \dots, X_n\), with expected
  value \(E[X_i] = \mu\) and \(Var[X_i] = \sigma^2 < \infty\), the
  sample average (centered and standardized) converges in distribution
  to a standard normal distribution at a root-\(n\) rate. Notationally,
  this is written as

  \[
  \sqrt{n} (\bar{X} - \mu) \overset{d}{\to} N(0, \sigma^2)
  \]

  \includegraphics[width=0.20833in,height=0.16667in]{images/chilipepper.png}
  A fun aside: this is only \emph{one} CLT, often referred to as the
  Levy CLT. There are other CLTs, such as the Lyapunov CLT and
  Lindeberg-Feller CLT!
\end{itemize}

\hypertarget{transforming-continuous-random-variables}{%
\subsection{Transforming Continuous Random
Variables}\label{transforming-continuous-random-variables}}

We will \emph{often} take at face value previously proven
\emph{relationships} between random variables. What I mean by this, as
an example, is that it is a nice (convenient) fact that a sum of two
independent normal random variables is \emph{still} normally
distributed, with a nice form for the mean and variance. In particular,
if \(X \sim N(\mu, \sigma^2)\) and \(Y \sim N(\theta, \nu^2)\), then
\(X + Y \sim N(\mu + \theta, \sigma^2 + \nu^2)\). Most frequently used
examples of these sorts of relationships can be found in the ``Related
Distributions'' section of the Wikipedia page for a given probability
distribution. Unless I explicitly ask you to derive/show how certain
variables are related to each other, you can just state the known
relationship, use it, and move on!

If I \emph{do} ask you to derive/show these things, there a few
different ways we can go about this. For this course, I only expect you
to know the ``CDF method'' for \emph{one function} of \emph{one random
variable}, as we'll demonstrate below.

\textbf{Theorem}. Let \(X\) be a continuous random variable with pdf
\(f_X(x)\). Define a new random variable \(Y = g(X)\), for nice*
functions \(g\). Then
\(f_Y(y) = f_X(g^{-1}(y)) \times \frac{1}{g'(g^{-1}(y))}\).

\includegraphics[width=0.20833in,height=0.16667in]{images/chilipepper.png}
*By \emph{nice} functions we mean functions that are strictly increasing
and smooth \emph{on the required range}. As an example, \(exp(x)\) is a
smooth, strictly increasing function; \(|x|\) is not on the \emph{whole
real line}, but \emph{is} from \((0, \infty)\) (where a lot of useful
pdfs are defined). For the purposes of this class, every function that
you will need to do this for will be ``nice.'' Note that there are also
considerations that need to be taken regarding the \emph{range} of
continuous random variables when considering transforming them. We will
mostly ignore these considerations in this class, but a technically
complete derivation (or proof) must consider them.

\textbf{Proof}. We can write

\[
\begin{align*}
    f_Y(y) & = \frac{\partial}{\partial y} F_Y(y) \\
    & = \frac{\partial}{\partial y} \Pr(Y \leq y) \\
    & = \frac{\partial}{\partial y} \Pr(g(X) \leq y) \\
    & = \frac{\partial}{\partial y} \Pr(X \leq g^{-1}(y)) \\
    & = \frac{\partial}{\partial y} F_X(g^{-1}(y)) \\
    & = f_X(g^{-1}(y)) \times \frac{\partial}{\partial y} g^{-1}(y) 
\end{align*} 
\]where to obtain the last equality we use chain rule! Now we require
some statistical trickery to continue\dots (note that this method is
called the ``CDF method'' because we go \emph{through} the CDF to derive
the distribution for \(Y\))

You will \emph{especially} see this in the Bayes chapter of our course
notes, but it is often true that our lives are made easier as
statisticians if we multiply things by one, or add zero. What exactly do
I mean? Rearranging gross looking formulas into things we are familiar
with (like pdfs, for example) often makes our lives easier and allows us
to avoid dealing with such grossness. Here, the grossness is less
obvious, but nonetheless relevant. Note that we can write

\[
\begin{align*}
    y & = y \\
    y & = g(g^{-1}(y)) \\
    \frac{\partial}{\partial y} y & = \frac{\partial}{\partial y} g(g^{-1}(y)) \\
    1 & = g'(g^{-1}(y)) \frac{\partial}{\partial y} g^{-1}(y) \hspace{1cm} \text{(chain rule again!)} \\
    \frac{1}{g'(g^{-1}(y))} & = \frac{\partial}{\partial y} g^{-1}(y)
\end{align*}
\]

The right-hand side should look familiar: it is exactly what we needed
to ``deal with'' in our proof! Returning to that proof, we have

\[
\begin{align*}
    f_Y(y) & = f_X(g^{-1}(y)) \times \frac{\partial}{\partial y} g^{-1}(y) \\
    & = f_X(g^{-1}(y)) \times \frac{1}{g'(g^{-1}(y))} 
\end{align*}
\]

as desired.

\hypertarget{worked-examples}{%
\section{Worked Examples}\label{worked-examples}}

\textbf{Problem 1:} Suppose \(X \sim Exponential(\lambda)\). Calculate
\(E[X]\) and \(Var[X]\).

We know that \(f(x) = \lambda e^{-\lambda x}\). If we can calculate
\(E[X]\) and \(E[X^2]\), then we're basically done! We can write

\[
\begin{align*}    
E[X] & = \int_0^\infty x \lambda e^{-\lambda x} dx \\    
& = \lambda \int_0^\infty x e^{-\lambda x} dx 
\end{align*}
\]

And now we need integration by parts! Set \(u = x\),
\(dv = e^{-\lambda x} dx\). Then \(du = 1dx\) and
\(v = \frac{-1}{\lambda} e^{-\lambda x}\). Since
\(\int u dv = uv - \int vdu\), we can continue

\[
\begin{align*}    
E[X] & = \lambda \int_0^\infty x e^{-\lambda x} dx \\    
& = \lambda \left( -\frac{x}{\lambda} e^{-\lambda x} \bigg|_0^\infty  - \int_0^\infty \frac{-1}{\lambda} e^{-\lambda x} dx \right) \\    
& = \lambda \left( - \int_0^\infty \frac{-1}{\lambda} e^{-\lambda x} dx \right) \\    
& = \lambda \left( \frac{-1}{\lambda^2} e^{-\lambda x}  \bigg|_0^\infty \right) \\    
& = \frac{-1}{\lambda} e^{-\lambda x}  \bigg|_0^\infty \\    
& = \frac{1}{\lambda} e^{-0} \\    
& = \frac{1}{\lambda}
\end{align*}
\]

We can follow a similar process to get \(E[X^2]\) (using the law of the
unconscious statistician!). We can write

\[
\begin{align*}
    E[X^2] & = \int_0^\infty x^2 \lambda e^{-\lambda x} dx \\
    & = \lambda \int_0^\infty x^2 e^{-\lambda x} dx 
\end{align*}
\]

And now we need integration by parts again! Set \(u = x^2\),
\(dv = e^{-\lambda x} dx\). Then \(du = 2xdx\) and
\(v = \frac{-1}{\lambda} e^{-\lambda x}\). Since
\(\int u dv = uv - \int vdu\), we can continue

\[
\begin{align*}
    E[X] & = \lambda \int_0^\infty x^2 e^{-\lambda x} dx \\
    & = \lambda \left( -\frac{x^2}{\lambda} e^{-\lambda x} \bigg|_0^\infty  - \int_0^\infty \frac{-2}{\lambda} xe^{-\lambda x} dx \right) \\
    & = \lambda \left( -\frac{x^2}{\lambda} e^{-\lambda x} \bigg|_0^\infty  + \frac{2}{\lambda} \int_0^\infty  xe^{-\lambda x} dx \right) \\
    & = \lambda \left( -\frac{x^2}{\lambda} e^{-\lambda x} \bigg|_0^\infty  + \frac{2}{\lambda^3} \right)\\
    & = \lambda \left( 0  + \frac{2}{\lambda^3} \right) \\
    & = \frac{2}{\lambda^2}
\end{align*}
\]

Now we can calculate \(Var[X] = E[X^2] - E[X]^2\) as \[
Var[X] = E[X^2] - E[X]^2 = \frac{2}{\lambda^2} - \frac{1}{\lambda^2} = \frac{1}{\lambda^2}
\] And so we have \(E[X] = \frac{1}{\lambda}\) and
\(Var[X] = \frac{1}{\lambda^2}\).

\textbf{Problem 2:} Show that an exponentially distributed random
variable is ``memoryless'', i.e.~show that
\(\Pr(X > s + x \mid X > s) = \Pr(X > x)\), \(\forall s\).

Recall that the CDF of an exponential distribution is given by
\(F(x) = 1-e^{-\lambda x}\). Thanks to Bayes rule, we can write

\[
\begin{align*}
    \Pr(X > s + x \mid X > s) & = \frac{\Pr(X > s + x , X > s)}{\Pr(X > s)} \\
    & = \frac{\Pr(X > s + x)}{\Pr(X > s)} \\
    & = \frac{1 - \Pr(X < s + x)}{1 - \Pr(X < s)} \\
    & = \frac{1 - F(s + x)}{1 - F(s)}
\end{align*}
\]

where the second equality is true because \(x > 0\). Then we can write

\[
\begin{align*}
    \Pr(X > s + x \mid X > s) & = \frac{1 - F(s + x)}{1 - F(s)} \\
    & = \frac{1 - \left(1 - e^{-\lambda(s + x)}\right)}{1 - \left(1 - e^{-\lambda s}\right)} \\
    & = \frac{e^{-\lambda(s + x)}}{e^{-\lambda s}} \\
    & = \frac{e^{-\lambda s - \lambda x}}{e^{-\lambda s}} \\
    & = e^{-\lambda x} \\
    & = 1 - F(x) \\
    & = \Pr(X > x)
\end{align*}
\]

and we're done!

\textbf{Problem 3:} Suppose \(X \sim Exponential(1/\lambda)\), and
\(Y \mid X \sim Poisson(X)\). Show that
\(Y \sim Geometric(1/(1 + \lambda))\).

Note that we can write \(f(x, y) = f(y \mid x) f(x)\), and
\(f(y) = \int f(x, y) dx\). Then

\[
f(x, y) = \left( \frac{1}{\lambda} e^{-x\lambda} \right) \left( \frac{x^y e^{-x}}{y!} \right)
\] And so,

\[
\begin{align*}
    f(y) & = \int f(x, y) dx \\
    & = \int \left( \frac{1}{\lambda} e^{-x\lambda} \right) \left( \frac{x^y e^{-x}}{y!} \right) dx \\
    & = \frac{1}{\lambda y!} \int x^y e^{-x(1 + \lambda)/\lambda} dx
\end{align*}
\]

And we can again use integration by parts! Let \(u = x^y\) and
\(dv = e^{-x(1 + \lambda)/\lambda} dx\). Then we have
\(du = yx^{y-1} dx\) and
\(v = \frac{\lambda}{1 + \lambda}e^{-x(1 + \lambda)/\lambda}\), and we
can write

\[
\begin{align*}
    f(y) & = \frac{1}{\lambda y!} \int x^y e^{-x(1 + \lambda)/\lambda} dx \\
    & = \frac{1}{\lambda y!} \left( x^y \frac{\lambda}{1 + \lambda}e^{-x(1 + \lambda)/\lambda} \bigg|_{x = 0}^{x = \infty}  - \int \frac{\lambda}{1 + \lambda}e^{-x(1 + \lambda)/\lambda} yx^{y-1} dx\right) \\
    & = \frac{1}{\lambda y!} \left( - \int \frac{\lambda}{1 + \lambda}e^{-x(1 + \lambda)/\lambda} yx^{y-1} dx \right) \\
    & = \frac{1}{\lambda y!} \left( \frac{\lambda }{1 + \lambda} \right) y \left( - \int e^{-x(1 + \lambda)/\lambda} x^{y-1} dx \right)
\end{align*}
\]

This \emph{looks} gross, but it's actually not so bad. Note that, since
\(Y\) is Poisson, it can only take integer values beginning at 1! Then
we can \emph{repeat} the process of integration by parts \(y\)
\emph{times} in order to get rid of \(x^{y\dots}\) term on the inside of
the integral. Specifically, each time we do this process we will pull
out a \(\left( \frac{\lambda }{1 + \lambda} \right)\), and a \(y - i\)
for the \(i\)th integration by parts step (try this one or two steps for
yourself to see how it will simplify if you find this unintuitive!). We
end up with,

\[
\begin{align*}
    f(y) & = \frac{1}{\lambda y!} \left( \frac{\lambda }{1 + \lambda} \right)^y y! \\
    & = \frac{1}{\lambda} \left(\frac{\lambda}{1 + \lambda}\right)^y
\end{align*}
\]

Now let \(p = \frac{1}{1 + \lambda}\). If we can show that
\(f(y) \sim Geometric(p)\) then we're done. Note that
\(1 - p = \lambda/(1 + \lambda)\). We have

\[
\begin{align*}
    f(y) & = \frac{1}{\lambda} (1 - p)^y \\
    & = \frac{1}{\lambda} (1 - p)^{y-1} (1-p) \\
    & = (1 - p)^{y-1} \frac{1}{\lambda} \left( \frac{\lambda}{1 + \lambda} \right) \\
    & = (1 - p)^{y-1} \left( \frac{1}{1 + \lambda} \right) \\
    & = (1 - p)^{y-1} p
\end{align*}
\]

which is exactly the pdf of a geometric random variable with parameter
\(p\) and trials that begin at 1 (as opposed to 0), as makes sense with
the Poisson distribution.

\textbf{Problem 4:} Suppose that \(X \sim N(\mu, \sigma^2)\), and let
\(Y = \frac{X - \mu}{\sigma}\). Find the distribution of \(Y\)
(simplifying all of your math will be useful for this problem).

To solve this problem, we can use the theorem on transforming continuous
random variables. We must first define our function \(g\) that relates
\(X\) and \(Y\). In this case, we have
\(g(a) = \frac{a - \mu}{\sigma}\). Now all we need to do is collect the
mathematical ``pieces'' we need to use theorem: \(g^{-1}(a)\), and
\(g'(a)\), and finally, the pdf of a normal random variable. We have

\[
\begin{align*}
    f_X(x) & = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp(-\frac{1}{2\sigma^2} (x - \mu)^2) \\
    g^{-1}(a) & = \sigma a + \mu \\
    g'(a) & = \frac{\partial}{\partial a} \left(\frac{a - \mu}{\sigma}\right) = \frac{1}{\sigma}
\end{align*}
\]

Putting it all together, we have

\[
\begin{align*}
    f_Y(y) & = f_X(g^{-1}(y)) \times \frac{1}{g'(g^{-1}(y))} \\
    & = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp(-\frac{1}{2\sigma^2} (\sigma y + \mu - \mu)^2) \times \sigma \\
    & = \frac{1}{\sqrt{2 \pi} \sigma} \exp(-\frac{1}{2\sigma^2} (\sigma y)^2) \times \sigma \\
    & = \frac{1}{\sqrt{2 \pi}} \exp(-\frac{1}{2\sigma^2} \sigma^2 y^2) \\
    & = \frac{1}{\sqrt{2 \pi}} \exp(-\frac{1}{2} y^2)
\end{align*}
\]

and note that this is the pdf of a normally distributed random variable
with mean \(0\) and variance \(1\)! Thus, we have shown that
\(\frac{X - \mu}{\sigma} \sim N(0,1)\). \textbf{Fun Fact:} If this
random variable reminds you of a Z-score, \emph{it should}!

\textbf{Problem 5:} Suppose the joint pdf of two random variables \(X\)
and \(Y\) is given by
\(f_{X,Y}(x,y) = \lambda \beta e^{-x\lambda - y\beta}\). Determine if
\(X\) and \(Y\) are independent, showing why or why not.

To determine whether \(X\) and \(Y\) are independent (or not), we need
to determine if their joint pdf is ``separable.'' Doing some algebra, we
can see that

\[
\begin{align*}    f_{X,Y}(x,y) & = \lambda \beta e^{-x \lambda - y\beta} \\    & = \lambda \beta e^{-x \lambda} e^{-y \beta} \\    & = \left( \lambda  e^{-x \lambda} \right) \left( \beta e^{-y \beta} \right) \end{align*}
\]

and so since we can write the joint distribution as a function of \(X\)
multiplied by a function of \(Y\), \(X\) and \(Y\) are independent (and
in this case, both have exponential distributions).

\textbf{Problem 6:} Suppose the joint pdf of two random variables \(X\)
and \(Y\) is given by
\(f_{X,Y}(x,y) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) \Gamma(\beta)} \binom{n}{y} x^{y + \alpha - 1} (1-x)^{n-y + \beta - 1}\).
Determine if \(X\) and \(Y\) are independent, showing why or why not.

To determine whether \(X\) and \(Y\) are independent (or not), we need
to determine if their joint pdf is ``separable.'' Right away, we should
note that a piece of the pdf contains \(x^y\), and therefore we are
\emph{never} going to be able to fully separate out this joint pdf into
a function of \(x\) times a function \(y\). Therefore, \(X\) and \(Y\)
are \emph{not} independent. In this case, we actually have
\(X \sim Beta(\alpha, \beta)\), and \(Y \mid X \sim Binomial(n, y)\)
(we'll return to this example in the Bayes chapter!).

\bookmarksetup{startatroot}

\hypertarget{maximum-likelihood-estimation}{%
\chapter{Maximum Likelihood
Estimation}\label{maximum-likelihood-estimation}}

In \emph{Probability}, you calculated probabilities of events by
assuming a probability model for data and then \emph{assuming you knew
the value of the parameters} in that model. In \emph{Mathematical
Statistics}, we will similarly write down a probability model but then
we will use observed data to \emph{estimate the value of the parameters}
in that model.

There is more than one technique that you can use to estimate the value
of an unknown parameter. You're already familiar with one
technique---\textbf{least squares estimation}---from \emph{STAT 155}.
We'll review the ideas behind that approach later in the course. To
start, we\textquotesingle ll explore two other widely used estimation
techniques: \textbf{maximum likelihood estimation} (this chapter) and
the \textbf{method of moments} (next chapter).

\hypertarget{introduction-to-mle}{%
\subsection{Introduction to MLE}\label{introduction-to-mle}}

To understand maximum likelihood estimation, we can first break down
each individual word in that phrase: (1) maximum, (2) likelihood, (3)
estimation. We'll start in reverse order.

Recall from your introductory statistics course that we are (often)
interested in estimating \emph{true, unknown \textbf{parameters}} in
statistics, using some data. Our best guess at the truth, based on the
data we observe / sample that we have, is an \textbf{\emph{estimate}} of
the truth (given some modeling assumptions). This is all the
``estimation'' piece is getting at here. We're going to be learning
about a method that produces estimates!

The likelihood piece may be less familiar to you. A likelihood is
essentially a fancy form of a function (see the Definitions section for
an \emph{exact} definition), that combines an assumed probability
distribution for your data, with some unknown parameters.* The key here
is that a likelihood is a \emph{function}. It may \emph{look} more
complicated than a function like \(y = mx + b\), but we can often
manipulate them in a similar fashion, which comes in handy when trying
to find the\ldots{}

Maximum! We've maximized functions before, and we can do it again! There
are ways to maximize functions numerically (using certain algorithms,
such as Newton-Raphson for example, which we'll cover in a later
chapter), but we will primarily focus on maximizing likelihoods
\emph{analytically} in this course to help us build intuition.

Recall from calculus: To maximize a function we\ldots{}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Take the derivative of the function
\item
  Set the derivative equal to zero
\item
  Solve!
\item
  (double check that the second derivative is negative, so that it's
  actually a maximum as opposed to a minimum)
\item
  (also check the endpoints)
\end{enumerate}

The last two steps we'll often skip in this class, since things have a
tendency to work out nicely with most likelihood functions. One final
thing to note (before checking out worked examples and making sure you
have a grasp on definitions and theorems) is that it is often
\emph{easier}

*\includegraphics[width=0.20833in,height=0.16667in]{images/chilipepper.png}
Note that distributions are only involved in \emph{parametric} methods,
as opposed to non-parametric and semi-parametric methods, the latter of
which are for independent study or a graduate course in statistics!

\hypertarget{learning-objectives-1}{%
\section{Learning Objectives}\label{learning-objectives-1}}

By the end of this chapter, you should be able to\ldots{}

\begin{itemize}
\item
  Derive maximum likelihood estimators for parameters of common
  probability density functions
\item
  Calculate maximum likelihood estimators ``by hand'' for common
  probability density functions
\item
  Explain (in plain English) why maximum likelihood estimation is an
  intuitive approach to estimating unknown parameters using a
  combination of (1) observed data, and (2) a distributional assumption
\end{itemize}

\hypertarget{reading-guide-1}{%
\section{Reading Guide}\label{reading-guide-1}}

Associated Readings: Chapter 5 (Introduction through Example 5.2.5)

\hypertarget{reading-questions-1}{%
\subsection{Reading Questions}\label{reading-questions-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  What is the intuition behind the maximum likelihood estimation (MLE)
  approach?
\item
  What are the typical steps to find a MLE? (see Ex 5.2.1, 5.2.2, and
  Case Study 5.2.1; work through at least one of these examples in
  detail, filling in any steps that the textbook left out)
\item
  Are there ever situations when the typical steps to finding a MLE
  don\textquotesingle t work? If so, what can we do instead to find the
  MLE? (see Ex 5.2.3, 5.2.4)
\item
  How do the steps to finding a MLE change when we have more than one
  unknown parameter? (see Ex 5.2.5)
\end{enumerate}

\hypertarget{definitions-1}{%
\section{Definitions}\label{definitions-1}}

You are expected to know the following definitions:

\textbf{Parameter}

Explanation

\textbf{Statistic/Estimator}

Explanation

\textbf{Likelihood Function}

Explanation

\textbf{Maximum Likelihood Estimate (MLE)}

Explanation

\textbf{Log-likelihood}

Explanation

\textbf{Order Statistic}

Explanation

\hypertarget{theorems-1}{%
\section{Theorems}\label{theorems-1}}

\hypertarget{worked-examples-1}{%
\section{Worked Examples}\label{worked-examples-1}}

\textbf{Problem 1:}

\bookmarksetup{startatroot}

\hypertarget{method-of-moments}{%
\chapter{Method of Moments}\label{method-of-moments}}

Under development\ldots{}

\bookmarksetup{startatroot}

\hypertarget{properties-of-estimators}{%
\chapter{Properties of Estimators}\label{properties-of-estimators}}

Under development\ldots{}

\bookmarksetup{startatroot}

\hypertarget{consistency}{%
\chapter{Consistency}\label{consistency}}

Under development\ldots{}

\bookmarksetup{startatroot}

\hypertarget{asymptotics-the-central-limit-theorem}{%
\chapter{Asymptotics \& the Central Limit
Theorem}\label{asymptotics-the-central-limit-theorem}}

Under development\ldots{}

\bookmarksetup{startatroot}

\hypertarget{computational-optimization}{%
\chapter{Computational Optimization}\label{computational-optimization}}

Under development\ldots{}

\bookmarksetup{startatroot}

\hypertarget{bayesian-inference}{%
\chapter{Bayesian Inference}\label{bayesian-inference}}

Under development\ldots{}

\bookmarksetup{startatroot}

\hypertarget{decision-theory}{%
\chapter{Decision Theory}\label{decision-theory}}

Under development\ldots{}

\bookmarksetup{startatroot}

\hypertarget{hypothesis-testing}{%
\chapter{Hypothesis Testing}\label{hypothesis-testing}}

Under development\ldots{}

\bookmarksetup{startatroot}

\hypertarget{references}{%
\chapter*{References}\label{references}}
\addcontentsline{toc}{chapter}{References}

\markboth{References}{References}

\hypertarget{refs}{}
\begin{CSLReferences}{0}{0}
\end{CSLReferences}



\end{document}
