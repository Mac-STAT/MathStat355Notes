[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MATH/STAT 455: Mathematical Statistics",
    "section": "",
    "text": "Welcome to Mathematical Statistics!\nThis book contains the course notes for MATH/STAT 455: Mathematical Statistics at Macalester College, as taught by Prof. Taylor Okonek. These notes draw from course notes created by Prof. Kelsey Grinde, and heavily from the course textbook, An Introduction to Mathematical Statistics and Its Applications by Richard Larsen and Morris Marx (6th Edition). Each chapter will contain (at a minimum):\n\nLearning Objectives\nReading Guide\nDefinitions\nTheorems\nWorked Examples\n\nI will be editing and adding to these notes throughout Spring 2024, so please check consistently for updates!\nIf you find any typos or have other questions, please email tokonek@macalester.edu."
  },
  {
    "objectID": "probability.html#learning-objectives",
    "href": "probability.html#learning-objectives",
    "title": "1  Probability: A Brief Review",
    "section": "1.1 Learning Objectives",
    "text": "1.1 Learning Objectives\nBy the end of this chapter, you should be able to…\n\nDistinguish between important probability models (e.g., Normal, Binomial)\nDerive the expectation and variance of a single random variable or a sum of random variables\nDefine the moment generating function and use it to find moments or identify pdfs"
  },
  {
    "objectID": "probability.html#associated-readings",
    "href": "probability.html#associated-readings",
    "title": "1  Probability: A Brief Review",
    "section": "1.2 Associated Readings",
    "text": "1.2 Associated Readings\nChapters 2-4 (pages 15-277)"
  },
  {
    "objectID": "probability.html#definitions",
    "href": "probability.html#definitions",
    "title": "1  Probability: A Brief Review",
    "section": "1.3 Definitions",
    "text": "1.3 Definitions\nYou are expected to know the following definitions:\nRandom Variable\nA random variable is a function that takes inputs from a sample space of all possible outcomes, and outputs real values or probabilities. As an example, consider a coin flip. The sample space of all possible outcomes consists of “heads” and “tails”, and each outcome is associated with a probability (50% each, for a fair coin). For our purposes, you should know that random variables have probability density (or mass) functions, and are either discrete or continuous based on the number of possible outcomes a random variable may take. Random variables are often denoted with capital Roman letters, like \\(X\\), \\(Y\\), \\(Z\\), etc.\nProbability density function (discrete, continuous)\n\nNote: I don’t care if you call a pmf a pdf… I will probably do this continuously throughout the semester. We don’t need to be picky about this in MATH/STAT 455.\n\nThere are many different accepted ways to write the notation for a pdf of a random variables. Any of the following are perfectly appropriate for this class: \\(f(x)\\), \\(\\pi(x)\\), \\(p(x)\\), \\(f_X(x)\\). I typically use either \\(\\pi\\) or \\(p\\), but might mix it up occasionally.\nKey things I want you to know about probability density functions:\n\n\\(\\pi(x) \\geq 0\\), everywhere. This should make sense (hopefully) because probabilities cannot be negative!\n\\(\\int_{-\\infty}^\\infty \\pi(x) = 1\\). This should also (hopefully) makes sense. Probabilities can’t be greater than one, and the probability of event occurring at all (ever) should be equal to one, if the event \\(x\\) is a random variable.\n\nCumulative distribution function (discrete, continuous)\nCumulative distribution functions we’ll typically write as \\(F_X(x)\\). or \\(F(x)\\), for short. It is important to know that\n\\[\nF_X(x) = \\Pr(X \\leq x),\n\\]\nor in words, “the cumulative distribution function is the probability that a random variable lies before \\(x\\).” If you write \\(\\Pr(X &lt; x)\\) instead of \\(\\leq\\), you’re fine. The probability that a random variable is exactly one number (for an RV with a continuous pdf) is zero anyway, so these are the same thing. Key things I want you to know about cumulative distribution functions:\n\n\\(F(x)\\) is non-decreasing. This is in part where the “cumulative” piece comes in to play. Recall that probabilities are basically integrals or sums. If we’re integrating over something positive, and our upper bound for our integral increases, the area under the curve (cumulative probability) will increase as well.\n\\(0 \\leq F(x) \\leq 1\\) (since probabilities have to be between zero and one!)\n\\(\\Pr(a &lt; X \\leq b) = F(a) - F(b)\\) (because algebra)\n\nJoint probability density function\nA joint probability density function is a probability distribution defined for more than one random variable at a time. For two random variables, \\(X\\) and \\(Z\\), we could write their joint density function as \\(f_{X,Z}(x, z)\\) , or \\(f(x,z)\\) for short. The joint density function encodes all sorts of fun information, including marginal distributions for \\(X\\) and \\(Z\\), and conditional distributions (see next bold definition). We can think of the joint pdf as listing all possible pairs of outputs from the density function \\(f(x,z)\\), for varying values of \\(x\\) and \\(z\\). Key things I want you to know about joint pdfs:\n\nHow to get a marginal pdf from a joint pdf:\nSuppose I want to know \\(f_X(x)\\), and I know \\(f_{X,Z}(x,z)\\). Then I can integrate or “average over” \\(Z\\) to get\n\\[\nf_X(x) = \\int f_{X,Z}(x,z)dz\n\\]\nThe relationship between conditional pdfs, marginal pdfs, joint pdfs, and Bayes’ theorem/rule\nHow to obtain a joint pdf for independent random variables: just multiply their marginal pdfs together! This is how we will (typically) think about likelihoods!\nHow to obtain a marginal pdf from a joint pdf when random variables are independent without integrating (think, “separability”)\n\nConditional probability density function\nA conditional pdf denotes the probability distribution for a (set of) random variable(s), given that the value for another (set of) random variable(s) is known. For two random variables, \\(X\\) and \\(Z\\), we could write the conditional distribution of \\(X\\) “given” \\(Z\\) as \\(f_{X \\mid Z}(x \\mid z)\\) , where the “conditioning” is denoted by a vertical bar (in LaTeX, this is typeset using “\\mid”). Key things I want you to know about conditional pdfs:\n\nThe relationship between conditional pdfs, marginal pdfs, joint pdfs, and Bayes’ theorem/rule\nHow to obtain a conditional pdf from a joint pdf (again, think Bayes’ rule)\nRelationship between conditional pdfs and independence (see next bold definition)\n\nIndependence\nTwo random variables \\(X\\) and \\(Z\\) are independent if and only if:\n\n\\(f_{X,Z}(x,z) = f_X(x) f_Z(z)\\) (their joint pdf is “separable”)\n\\(f_{X\\mid Z}(x\\mid z) = f_X(x)\\) (the pdf for \\(X\\) does not depend on \\(Z\\) in any way)\nNote that the “opposite” is also true: \\(f_{Z\\mid X}(z\\mid x) = f_Z(z)\\)\n\nIn notation, we denote that two variables are independent as \\(X \\perp\\!\\!\\!\\perp Z\\), or \\(X \\perp Z\\). In LaTeX, the latter is typeset as “\\perp”, and the former is typeset as “\\perp\\!\\!\\!\\perp”. As a matter of personal preference, I (Taylor) prefer \\(\\perp\\!\\!\\!\\perp\\), but I don’t like typing it out every time. Consider using the “\\newcommand” functionality in LaTeX to create a shorthand for this for your documents!\nExpected Value / Expectation\nThe expectation (or expected value) of a random variable is defined as:\n\\[\nE[X] = \\int_{-\\infty}^\\infty x f(x) dx\n\\]\nExpected value is a weighted average, where the average is over all possible values a random variable can take, weighted by the probability that those values occur. Key things I want you to know about expectation:\n\nThe relationship between expectation, variance, and moments (specifically, that \\(E[X]\\) is the 1st moment!)\nThe “law of the unconscious statistician” (see the Theorems section of this chapter)\nExpectation of linear transformations of random variables (see Theorems section of this chapter)\n\nVariance\nThe variance of a random variable is defined as:\n\\[\nVar[X] = E[(X - E[X])^2] = E[X^2] - E[X]^2\n\\]\nIn words, we can read this as “the expected value of the squared deviation from the mean” of a random variable \\(X\\). Key things I want you to know about variance:\n\nThe relationship between expectation, variance, and moments (hopefully clear, given the formula for variance)\nThe relationship between variance and standard deviation: \\(Var(X) = sd(X)^2\\)\nThe relationship between variance and covariance: \\(Var(X) = Cov(X, X)\\)\n\\(Var(X) \\geq 0\\). This should make sense, given that we’re taking the expectation of something “squared” in order to calculate it!\n\\(Var(c) = 0\\) for any constant, \\(c\\).\nVariance of linear transformations of random variables (see Theorems section of this chapter)\n\n\\(r^{th}\\) moment\nThe \\(r^{th}\\) moment of a probability distribution is given by \\(E[X^r]\\). For example, when \\(r = 1\\), the \\(r^{th}\\) moment is just the expectation of the random variable \\(X\\). Key things I want you to know about moments:\n\nThe relationship between moments, expectation, and variance\n\nFor example, if you know the first and second moments of a distribution, you should be able to calculate the variance of a random variable with that distribution!\n\nThe relationship between moments and moment generating functions (see Theorems section of this chapter)\n\nCovariance\nThe covariance of two random variables is a measure of their joint variability. We denote the covariance of two random variables \\(X\\) and \\(Z\\) as \\(Cov(X,Z)\\), and\n\\[\nCov(X, Z) = E[(X - E[X])(Y - E[Y])] = E[XY] - E[X]E[Y]\n\\]\nSome things I want you to know about covariance:\n\n\\(Cov(X, X) = Var(X)\\)\n\\(Cov(X, Y) = Cov(Y, X)\\) (order doesn’t matter)\n\nMoment Generating Function\nYou are also expected to know the probability distributions contained in Table 1, below. Note that you do not need to memorize the pdfs for these distributions, but you should be familiar with what types of random variables (continuous/quantitative, categorical, integer-valued, etc.) may take on different distributions. The more familiar you are with the forms of the pdfs, the easier/faster it will be to work through problem sets and quizzes.\n\nTable 1. Table of main probability distributions we will work with for MATH/STAT 455.\n\n\n\n\n\n\n\nDistribution\nPDF/PMF\nParameters\n\n\n\n\nUniform\n\\(\\pi(x) = \\frac{1}{\\beta - \\alpha}\\)\n\\(\\alpha \\in \\mathbb{R}\\), \\(\\beta\\in \\mathbb{R}\\)\n\n\nNormal\n\\(\\pi(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp(-\\frac{1}{2\\sigma^2} (x - \\mu)^2)\\)\n\\(\\mu \\in \\mathbb{R}\\), \\(\\sigma &gt; 0\\)\n\n\nMultivariate Normal\n\\(\\pi(\\textbf{x}) - (2\\pi)^{-k/2} |\\Sigma|^{-1/2} \\exp(-\\frac{1}{2}(\\textbf{x} - \\mu)^\\top \\Sigma^{-1}(\\textbf{x} - \\mu)))\\)\n\\(\\mu \\in \\mathbb{R}^k\\), \\(\\Sigma \\in \\mathbb{R}^{k\\times k}\\) , positive semi-definite (in practice, almost always positive definite)\n\n\nGamma\n\\(\\pi(x) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}x^{\\alpha - 1} e^{-\\beta x}\\)\n\\(\\alpha \\text{ (shape)}, \\beta \\text{ (rate)} &gt; 0\\)\n\n\nChi-square\n\\(\\pi(x) = \\frac{2^{-\\nu/2}}{\\Gamma(\\nu/2)} x^{\\nu/2 - 1}e^{-x/2})\\)\n\\(\\nu &gt; 0\\)\n\n\nExponential\n\\(\\pi(x) = \\beta e^{-\\beta x}\\)\n\\(\\beta &gt; 0\\)\n\n\nStudent-$t$\n\\(\\pi(x) = \\frac{\\Gamma((\\nu + 1)/2)}{\\Gamma(\\nu/2) \\sqrt{\\nu \\pi}} (1 + \\frac{x^2}{\\nu})^{-(\\nu + 1)/2}\\)\n\\(\\nu &gt; 0\\)\n\n\nBeta\n\\(\\pi(x) = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha - 1}(1 - x)^{\\beta - 1}\\)\n\\(\\alpha, \\beta &gt; 0\\)\n\n\nPoisson\n\\(\\pi(x) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\\)\n\\(\\lambda &gt; 0\\)\n\n\nBinomial\n\\(\\pi(x) = \\binom{n}{x} p^{x} (1 - p)^{n - x}\\)\n\\(p \\in [0,1], n = \\{0, 1, 2, \\dots\\}\\)\n\n\nMultinomial\n\\(\\pi(\\textbf{x}) = \\frac{n!}{x_1! \\dots x_k!} p_1^{x_1} \\dots p_k^{x_k}\\)\n\\(p_i &gt; 0\\), \\(p_1 + \\dots + p_k = 1\\), \\(n = \\{0, 1, 2, \\dots \\}\\)\n\n\nNegative Binomial\n\\(\\pi(x) = \\binom{k + r - 1}{k} (1-p)^k p^r\\)\n\\(r &gt; 0\\), \\(p \\in [0,1]\\)"
  },
  {
    "objectID": "probability.html#theorems",
    "href": "probability.html#theorems",
    "title": "1  Probability: A Brief Review",
    "section": "1.4 Theorems",
    "text": "1.4 Theorems\n\nLaw of Total Probability\n\\[\nP(A) = \\sum_n P(A \\cap B_n),\n\\]or\n\\[\nP(A) = \\sum_n P(A \\mid B_n) P(B_n)\n\\]\nBayes’ Theorem\n\\[\n\\pi(A \\mid B) = \\frac{\\pi(B \\mid A) \\pi(A)}{\\pi(B)}\n\\]\nRelationship between pdf and cdf\n\\[\nF_Y(y) = \\int_{-\\infty}^y f_Y(t)dt\n\\]\n\\[\n\\frac{\\partial}{\\partial y}F_Y(y) = f_Y(y)\n\\]\nExpectation of random variables\n\\[\nE[X] = \\int_{-\\infty}^\\infty x f(x) dx\n\\]\n\\[\nE[X^2] = \\int_{-\\infty}^\\infty x^2 f(x) dx\n\\]\n\n“Law of the Unconscious Statistician”\n\\[\nE[g(X)] = \\int_{-\\infty}^\\infty g(x)f(x)dx\n\\]\n\nExpectation and variance of linear transformations of random variables\n\\[\nE[cX + b] = c E[X] + b\n\\]\n\\[\nVar[cX + b] = c^2 Var[X]\n\\]\nRelationship between mean and variance\n\\[\nVar[X] = E[(X - E[X])^2] = E[X^2] - E[X]^2\n\\]\nAlso, recall that \\(Cov[X, X] = Var[X]\\).\nFinding a marginal pdf from a joint pdf\n\\[\nf_X(x) = \\int_{-\\infty}^\\infty f_{X,Y}(x, y) dy\n\\]\nIndependence of random variables and joint pdfs\nIf two random variables are independent, their joint pdf will be separable. For example, if \\(X\\) and \\(Y\\) are independent, we could write\n\\[\nf_{X,Y}(x, y) = f_{X}(x)f_Y(y)\n\\]\nExpected value of a product of independent random variables\nSuppose random variables \\(X_1, \\dots, X_n\\) are independent. Then we can write,\n\\[\nE\\left[\\prod_{i = 1}^n X_i\\right] = \\prod_{i = 1}^n E[X_i]\n\\]\nCovariance of independent random variables\nIf \\(X\\) and \\(Y\\) are independent, then \\(Cov(X, Y) = 0\\). We can show this by noting that\n\n\\[\n\\begin{align}\nCov(X, Y) & = E[(X - E[X])(Y - E[Y])] \\\\\n& = E[XY - XE[Y] - YE[X] + E[X]E[Y]] \\\\\n& = E[XY] - E[XE[Y]] - E[YE[X]] + E[X]E[Y] \\\\\n& =  2E[X]E[Y] - 2E[X]E[Y] \\\\\n& = 0\n\\end{align}\n\\]\n\nUsing MGFs to find moments\nRecall that the moment generating function of a random variable \\(X\\), denoted by \\(M_X(t)\\) is\n\\[\nM_X(t) = E[e^{tX}]\n\\]\nThen the \\(n\\)th moment of the probability distribution for \\(X\\) , \\(E[X^n]\\), is given by\n\\[\n\\frac{\\partial M_X}{\\partial t^n} \\Bigg|_{t = 0}\n\\]\nwhere the above reads as “the \\(n\\)th derivative of the moment generating function, evaluated at \\(t = 0\\).”\nUsing MGFs to identify pdfs\nMGFs uniquely identify probability density functions. If \\(X\\) and \\(Y\\) are two random variables where for all values of \\(t\\), \\(M_X(t) = M_Y(t)\\), then \\(F_X(x) = F_Y(y)\\).\nCentral Limit Theorem\nThe classical CLT states that for independent and identically distributed (iid) random variables \\(X_1, \\dots, X_n\\), with expected value \\(E[X_i] = \\mu\\) and \\(Var[X_i] = \\sigma^2 &lt; \\infty\\), the sample average (centered and standardized) converges in distribution to a standard normal distribution at a root-\\(n\\) rate. Notationally, this is written as\n\\[\n\\sqrt{n} (\\bar{X} - \\mu) \\overset{d}{\\to} N(0, \\sigma^2)\n\\]\n A fun aside: this is only one CLT, often referred to as the Levy CLT. There are other CLTs, such as the Lyapunov CLT and Lindeberg-Feller CLT!"
  },
  {
    "objectID": "probability.html#worked-examples",
    "href": "probability.html#worked-examples",
    "title": "1  Probability: A Brief Review",
    "section": "1.5 Worked Examples",
    "text": "1.5 Worked Examples\nProblem 1: Suppose \\(X \\sim Exponential(\\lambda)\\). Calculate \\(E[X]\\) and \\(Var[X]\\).\nWe know that \\(f(x) = \\lambda e^{-\\lambda x}\\). If we can calculate \\(E[X]\\) and \\(E[X^2]\\), then we’re basically done! We can write\n\\[\n\\begin{align*}    \nE[X] & = \\int_0^\\infty x \\lambda e^{-\\lambda x} dx \\\\    \n& = \\lambda \\int_0^\\infty x e^{-\\lambda x} dx\n\\end{align*}\n\\]\nAnd now we need integration by parts! Set \\(u = x\\), \\(dv = e^{-\\lambda x} dx\\). Then \\(du = 1dx\\) and \\(v = \\frac{-1}{\\lambda} e^{-\\lambda x}\\). Since \\(\\int u dv = uv - \\int vdu\\), we can continue\n\\[\n\\begin{align*}    \nE[X] & = \\lambda \\int_0^\\infty x e^{-\\lambda x} dx \\\\    \n& = \\lambda \\left( -\\frac{x}{\\lambda} e^{-\\lambda x} \\bigg|_0^\\infty  - \\int_0^\\infty \\frac{-1}{\\lambda} e^{-\\lambda x} dx \\right) \\\\    \n& = \\lambda \\left( - \\int_0^\\infty \\frac{-1}{\\lambda} e^{-\\lambda x} dx \\right) \\\\    \n& = \\lambda \\left( \\frac{-1}{\\lambda^2} e^{-\\lambda x}  \\bigg|_0^\\infty \\right) \\\\    \n& = \\frac{-1}{\\lambda} e^{-\\lambda x}  \\bigg|_0^\\infty \\\\    \n& = \\frac{1}{\\lambda} e^{-0} \\\\    \n& = \\frac{1}{\\lambda}\n\\end{align*}\n\\]\nWe can follow a similar process to get \\(E[X^2]\\) (using the law of the unconscious statistician!). We can write\n\\[\\begin{align*}\n    E[X^2] & = \\int_0^\\infty x^2 \\lambda e^{-\\lambda x} dx \\\\\n    & = \\lambda \\int_0^\\infty x^2 e^{-\\lambda x} dx\n\\end{align*}\\]\nAnd now we need integration by parts again! Set \\(u = x^2\\), \\(dv = e^{-\\lambda x} dx\\). Then \\(du = 2xdx\\) and \\(v = \\frac{-1}{\\lambda} e^{-\\lambda x}\\). Since \\(\\int u dv = uv - \\int vdu\\), we can continue\n\\[\\begin{align*}\n    E[X] & = \\lambda \\int_0^\\infty x^2 e^{-\\lambda x} dx \\\\\n    & = \\lambda \\left( -\\frac{x^2}{\\lambda} e^{-\\lambda x} \\bigg|_0^\\infty  - \\int_0^\\infty \\frac{-2}{\\lambda} xe^{-\\lambda x} dx \\right) \\\\\n    & = \\lambda \\left( -\\frac{x^2}{\\lambda} e^{-\\lambda x} \\bigg|_0^\\infty  + \\frac{2}{\\lambda} \\int_0^\\infty  xe^{-\\lambda x} dx \\right) \\\\\n    & = \\lambda \\left( -\\frac{x^2}{\\lambda} e^{-\\lambda x} \\bigg|_0^\\infty  + \\frac{2}{\\lambda^3} \\right)\\\\\n    & = \\lambda \\left( 0  + \\frac{2}{\\lambda^3} \\right) \\\\\n    & = \\frac{2}{\\lambda^2}\n\\end{align*}\\]\nNow we can calculate \\(Var[X] = E[X^2] - E[X]^2\\) as \\[\nVar[X] = E[X^2] - E[X]^2 = \\frac{2}{\\lambda^2} - \\frac{1}{\\lambda^2} = \\frac{1}{\\lambda^2}\n\\] And so we have \\(E[X] = \\frac{1}{\\lambda}\\) and \\(Var[X] = \\frac{1}{\\lambda^2}\\).\nProblem 2: Show that an exponentially distributed random variable is “memoryless”, i.e. show that \\(\\Pr(X &gt; s + x \\mid X &gt; s) = \\Pr(X &gt; x)\\), \\(\\forall s\\).\nRecall that the CDF of an exponential distribution is given by \\(F(x) = 1-e^{-\\lambda x}\\). Thanks to Bayes rule, we can write\n\\[\\begin{align*}\n    \\Pr(X &gt; s + x \\mid X &gt; s) & = \\frac{\\Pr(X &gt; s + x , X &gt; s)}{\\Pr(X &gt; s)} \\\\\n    & = \\frac{\\Pr(X &gt; s + x)}{\\Pr(X &gt; s)} \\\\\n    & = \\frac{1 - \\Pr(X &lt; s + x)}{1 - \\Pr(X &lt; s)} \\\\\n    & = \\frac{1 - F(s + x)}{1 - F(s)}\n\\end{align*}\\] where the second equality is true because \\(x &gt; 0\\). Then we can write\n\\[\\begin{align*}\n    \\Pr(X &gt; s + x \\mid X &gt; s) & = \\frac{1 - F(s + x)}{1 - F(s)} \\\\\n    & = \\frac{1 - \\left(1 - e^{-\\lambda(s + x)}\\right)}{1 - \\left(1 - e^{-\\lambda s}\\right)} \\\\\n    & = \\frac{e^{-\\lambda(s + x)}}{e^{-\\lambda s}} \\\\\n    & = \\frac{e^{-\\lambda s - \\lambda x}}{e^{-\\lambda s}} \\\\\n    & = e^{-\\lambda x} \\\\\n    & = 1 - F(x) \\\\\n    & = \\Pr(X &gt; x)\n\\end{align*}\\]\nand we’re done!\nProblem 3: Suppose \\(X \\sim Exponential(1/\\lambda)\\), and \\(Y \\mid X \\sim Poisson(X)\\). Show that \\(Y \\sim Geometric(1/(1 + \\lambda))\\).\nNote that we can write \\(f(x, y) = f(y \\mid x) f(x)\\), and \\(f(y) = \\int f(x, y) dx\\). Then\n\\[\nf(x, y) = \\left( \\frac{1}{\\lambda} e^{-x\\lambda} \\right) \\left( \\frac{x^y e^{-x}}{y!} \\right)\n\\] And so, \\[\\begin{align*}\n    f(y) & = \\int f(x, y) dx \\\\\n    & = \\int \\left( \\frac{1}{\\lambda} e^{-x\\lambda} \\right) \\left( \\frac{x^y e^{-x}}{y!} \\right) dx \\\\\n    & = \\frac{1}{\\lambda y!} \\int x^y e^{-x(1 + \\lambda)/\\lambda} dx\n\\end{align*}\\]\nAnd we can again use integration by parts! Let \\(u = x^y\\) and \\(dv = e^{-x(1 + \\lambda)/\\lambda} dx\\). Then we have \\(du = yx^{y-1} dx\\) and \\(v = \\frac{\\lambda}{1 + \\lambda}e^{-x(1 + \\lambda)/\\lambda}\\), and we can write\n\\[\\begin{align*}\n    f(y) & = \\frac{1}{\\lambda y!} \\int x^y e^{-x(1 + \\lambda)/\\lambda} dx \\\\\n    & = \\frac{1}{\\lambda y!} \\left( x^y \\frac{\\lambda}{1 + \\lambda}e^{-x(1 + \\lambda)/\\lambda} \\bigg|_{x = 0}^{x = \\infty}  - \\int \\frac{\\lambda}{1 + \\lambda}e^{-x(1 + \\lambda)/\\lambda} yx^{y-1} dx\\right) \\\\\n    & = \\frac{1}{\\lambda y!} \\left( - \\int \\frac{\\lambda}{1 + \\lambda}e^{-x(1 + \\lambda)/\\lambda} yx^{y-1} dx \\right) \\\\\n    & = \\frac{1}{\\lambda y!} \\left( \\frac{\\lambda }{1 + \\lambda} \\right) y \\left( - \\int e^{-x(1 + \\lambda)/\\lambda} x^{y-1} dx \\right)\n\\end{align*}\\]\nThis gross, but it’s actually not so bad. Note that, since \\(Y\\) is Poisson, it can only take integer values beginning at 1! Then we can the process of integration by parts \\(y\\) in order to get rid of \\(x^{y\\dots}\\) term on the inside of the integral. Specifically, each time we do this process we will pull out a \\(\\left( \\frac{\\lambda }{1 + \\lambda} \\right)\\), and a \\(y - i\\) for the \\(i\\)th integration by parts step (try this one or two steps for yourself to see how it will simplify if you find this unintuitive!). We end up with,\n\\[\\begin{align*}\n    f(y) & = \\frac{1}{\\lambda y!} \\left( \\frac{\\lambda }{1 + \\lambda} \\right)^y y! \\\\\n    & = \\frac{1}{\\lambda} \\left(\\frac{\\lambda}{1 + \\lambda}\\right)^y\n\\end{align*}\\]\nNow let \\(p = \\frac{1}{1 + \\lambda}\\). If we can show that \\(f(y) \\sim Geometric(p)\\) then we’re done. Note that \\(1 - p = \\lambda/(1 + \\lambda)\\). We have\n\\[\\begin{align*}\n    f(y) & = \\frac{1}{\\lambda} (1 - p)^y \\\\\n    & = \\frac{1}{\\lambda} (1 - p)^{y-1} (1-p) \\\\\n    & = (1 - p)^{y-1} \\frac{1}{\\lambda} \\left( \\frac{\\lambda}{1 + \\lambda} \\right) \\\\\n    & = (1 - p)^{y-1} \\left( \\frac{1}{1 + \\lambda} \\right) \\\\\n    & = (1 - p)^{y-1} p\n\\end{align*}\\] which is exactly the pdf of a geometric random variable with parameter \\(p\\) and trials that begin at 1 (as opposed to 0), as makes sense with the Poisson distribution."
  },
  {
    "objectID": "mle.html",
    "href": "mle.html",
    "title": "2  Maximum Likelihood Estimation",
    "section": "",
    "text": "Under development…"
  },
  {
    "objectID": "mom.html",
    "href": "mom.html",
    "title": "3  Method of Moments",
    "section": "",
    "text": "Under development…"
  },
  {
    "objectID": "properties.html",
    "href": "properties.html",
    "title": "4  Properties of Estimators",
    "section": "",
    "text": "Under development…"
  },
  {
    "objectID": "consistency.html",
    "href": "consistency.html",
    "title": "5  Consistency",
    "section": "",
    "text": "Insert text here\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "asymptotics.html",
    "href": "asymptotics.html",
    "title": "6  Asymptotics & the Central Limit Theorem",
    "section": "",
    "text": "Under development…"
  },
  {
    "objectID": "computation.html",
    "href": "computation.html",
    "title": "7  Computational Optimization",
    "section": "",
    "text": "Under development…"
  },
  {
    "objectID": "bayes.html",
    "href": "bayes.html",
    "title": "8  Bayesian Inference",
    "section": "",
    "text": "Insert text here\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "decision.html",
    "href": "decision.html",
    "title": "9  Decision Theory",
    "section": "",
    "text": "Insert text here\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "hypothesis.html",
    "href": "hypothesis.html",
    "title": "10  Hypothesis Testing",
    "section": "",
    "text": "Under development…"
  },
  {
    "objectID": "probability.html#reading-guide",
    "href": "probability.html#reading-guide",
    "title": "1  Probability: A Brief Review",
    "section": "1.2 Reading Guide",
    "text": "1.2 Reading Guide\nAssociated Readings: Chapters 2-4 (pages 15-277)\n\n1.2.1 Reading Questions\n\nWhich probability distributions are appropriate for quantitative (continuous) random variables?\nWhich probability distributions are appropriate for categorical random variables?\nIndependently and Identically Distributed (iid) random variables are an incredibly important assumption involved in many statistical methods. Why do you think it might be important/useful for random variables to have this property?"
  }
]