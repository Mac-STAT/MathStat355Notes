# Properties of Estimators

Now that we've developed the tools for deriving estimators of unknown parameters, we can start thinking about different metrics for determining how "good" our estimators actually are. In general, we like our estimators to be:

-   **Unbiased**: Our estimate should be estimating *what it's supposed to be estimating*, for lack of a better phrase. Bias (or, unbiased-ness, in this case) is related to accuracy. In introductory statistics, you likely discussed sample bias (or, whether or not the data you collect is representative of the population you are trying to make inference on) and information bias (or, whether the values of the data you collect are representative of the people who report them). If you have a biased sample or biased information, your estimates (think, regression coefficients) are likely going to misrepresent true relationships in the population. Bias of *estimates* has a very specific definition in statistical theory that is *distinct* from sample bias and information bias. Questions of sample bias and information bias are important to consider when collecting and analyzing data, and questions of whether or not our estimates are biased are important to consider *prior* to analyzing data.

-   **Precise:** In short, if our estimates are wildly uncertain (think, gigantic confidence intervals), they'll essentially be of no use to us from a practical perspective. As an extreme example, consider how you would feel if a new cancer drug was released with *very* severe side-effects, but scientists noted that the drug would increase cancer patients expected survival time by somewhere between 1 and 700 days. Are we really certain enough, in this case, that the benefits of the drug outweigh the potential costs? What if instead, the expected survival time would increase between 650 and 700 days? Would that change your answer? These types of questions are precisely (ha!) why precision is important. Again, you've likely discussed precision (colloquially) in an introductory statistics course. In statistical theory, precision (similar to bias) has a very specific definition. So long as our estimates are unbiased, we want to minimize variance (and therefore increase precision) as much as we possibly can. Even at the same sample size, some estimates are more precise than others, which we'll explore in this chapter.

### The Bias-Variance Trade-off {.unnumbered .unlisted}

Notes...

## Learning Objectives

By the end of this chapter, you should be able to...

-   Calculate bias and variance of various estimators for unknown parameters

-   Explain the distinction between bias and variance colloquially in terms of precision and accuracy, and why these properties are important

-   Compare estimators in terms of their relative efficiency

-   Justify why there exists a bias-variance trade-off, and explain what consequences this may have when comparing estimators

## Reading Guide

Associated Readings: Chapter 5, Section 5.4 ("Properties of Estimators") & 5.5 ("Minimum-Variance Estimators: The Cramér-Rao Lower Bound")

### Reading Questions

1.  Intuitively, what is the difference between bias and precision?

2.  What are the typical steps to checking if an estimator is unbiased? (see Examples 5.4.2, 5.4.3, and 5.4.4 in the textbook)

3.  How can we construct unbiased estimators? (see comment in Example 5.4.2 and 5.4.4)

4.  If an estimator is unbiased, is it also *asymptotically* unbiased? If an estimator is asymptotically unbiased, is it necessarily unbiased?

5.  When comparing estimators, how can we determine which estimator is more efficient? (see Examples 5.4.5 and 5.4.6)

6.  Describe, in your own words, what the Cramér-Rao inequality tells us.

7.  What is the difference between a UMVUE and an efficient estimator? Does one imply the other? (see the Comment below Definition 5.5.2)

## Definitions

You are expected to know the following definitions:

**Unbiased**

An estimator $\hat{\theta} = g(X_1, \dots, X_n)$ is an unbiased estimator for $\theta$ if $E[\hat{\theta}] = \theta$, for all $\theta$.

**Asymptotically Unbiased**

An estimator $\hat{\theta} = g(X_1, \dots, X_n)$ is an *asymptotically* unbiased estimator for $\theta$ if $\underset{n \to \infty}{\text{lim}} E[\hat{\theta}] = \theta$.

**Precision**

The precision of a random variable $X$ is given by $\frac{1}{Var(X)}$.

**Mean Squared Error (MSE)**

The mean squared error of an estimator is given by

$$
MSE(\hat{\theta}) = E[(\hat{\theta} - \theta)^2] = Var(\hat{\theta}) + Bias(\hat{\theta})^2
$$

**Relative Efficiency**

The relative efficiency of an estimator $\hat{\theta}_1$ with respect to an estimator $\hat{\theta}_2$ is the ratio $Var(\hat{\theta}_2)/Var(\hat{\theta}_1)$.

**Uniformly Minimum-Variance Unbiased Estimator (UMVUE)**

An estimator $\hat{\theta}^*$ is the UMVUE if, for all estimators $\hat{\theta}$ in the class of unbiased estimators $\Theta$,

$$
Var(\hat{\theta}^*) \leq Var(\theta)
$$

**Score**

The score is defined as the first partial derivative with respect to $\theta$ of the log-likelihood function, given by

$$
\frac{\partial}{\partial \theta} \log L(\theta \mid x)
$$

**Information Matrix**

The information matrix\* $I(\theta)$ for a collection of iid random variables $X_1, \dots, X_n$ is the variance of the score, given by

$$
I(\theta) = E \left[ \left( \frac{\partial}{\partial \theta} \log L(\theta \mid x) \right)^2\right]
$$

Note that the above formula *is* in fact the variance of the score, since we can show that the *expectation* of the score is 0 (under some regularity conditions). This is shown as part of the proof of the C-R lower bound in the Theorems section of this chapter.

The information matrix is sometimes written in terms of a pdf for a single random variable as opposed to a likelihood (this is what our textbook does, for example). In this case, we have $I(\theta) = n I_1(\theta)$, where the $I_1(\theta)$ on the right-hand side is defined as $E \left[ \left( \frac{\partial}{\partial \theta} \log f_X(x \mid \theta) \right)^2\right]$. Sometimes (as in the textbook) $I_1(\theta)$ is written without the subscript $1$ which is a slight abuse of notation that is endlessly confusing (to me, at least). For this set of course notes, we'll always specify the information matrix in terms of a pdf for a single random variable with the subscript $1$, for clarity.

\*The information matrix is often referred to as the Fisher Information matrix, as it was developed by Sir Ronald Fisher. Fisher developed *much* of the core, statistical theory that we use today. He was also the founding chairman of the University of Cambridge Eugenics Society, and contributed to a large body of scientific work and public policy that promoted racist and classist ideals.

## Theorems

**Covariance Inequality** (based on the Cauchy-Schwarz inequality)

Let $X$ and $Y$ be random variables. Then,

$$
Var(X) \geq \frac{Cov(X, Y)^2}{Var(Y)}
$$

The proof is quite clear on [Wikipedia](https://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality).

**Cramér-Rao Lower Bound**

Let $f_Y(y \mid \theta)$ be a pdf with nice\* conditions, and let $Y_1, \dots, Y_n$ be a random sample from $f_Y(y \mid \theta)$. Let $\hat{\theta}$ be *any* unbiased estimator of $\theta$. Then

```{=tex}
\begin{align*} 
Var(\hat{\theta}) & \geq \left\{ E\left[ \left( \frac{\partial \log( L(\theta \mid y))}{\partial \theta}\right)^2\right]\right\}^{-1} \\
& = \left\{ E\left[ \left( \frac{\partial^2 \log( L(\theta \mid y))}{\partial \theta^2}\right)^2\right]\right\}^{-1} \\
& = \frac{1}{I(\theta)}
\end{align*}
```
\*our nice conditions that we need are that $f_Y(y \mid \theta)$ has continuous first- and second-order derivatives, which would quickly discover we need by looking at the form for the C-R lower bound, and that the set of values $y$ where $f_Y(y \mid \theta) \neq 0$ does not depend on $\theta$. If you are familiar with the concept of the "support" of a function, that is where this second condition comes from. The key here is that this condition allows to interchange derivatives and integrals, in particular, $\frac{\partial}{\partial \theta} \int f(x) dx = \int \frac{\partial}{\partial \theta} f(x)dx$, which we'll need to complete the proof.

**Proof.**

Let $X = \frac{\partial \log L(\theta \mid \textbf{y})}{\partial \theta}$. By the Covariance Inequality,

$$
Var(\hat{\theta}) \geq \frac{Cov(\hat{\theta},X)^2}{Var(X)}
$$

and so if we can show

```{=tex}
\begin{align*} 
\frac{Cov(\hat{\theta},X)^2}{Var(X)} & = \left\{ E\left[ \left( \frac{\partial \log( L(\theta \mid \textbf{y}))}{\partial \theta}\right)^2\right]\right\}^{-1}  \\
& = \frac{1}{I(\theta)}
\end{align*}
```
then we're done, as this is the C-R lower bound. Note first that

```{=tex}
\begin{align*} 
E[X] & = \int x f_Y(\textbf{y} \mid \theta) d\textbf{y} \\
& = \int \left( \frac{\partial \log L(\theta \mid \textbf{y})}{\partial \theta} \right)  f_Y(\textbf{y} \mid \theta) d\textbf{y} \\
& = \int \left( \frac{\partial \log f_Y(\textbf{y} \mid \theta)}{\partial \theta} \right)  f_Y(\textbf{y} \mid \theta) d\textbf{y} \\
& = \int \frac{\frac{\partial}{\partial \theta} f_Y(\textbf{y} \mid \theta)}{ f_Y(\textbf{y} \mid \theta)} f_Y(\textbf{y} \mid \theta) d\textbf{y} \\
& = \int \frac{\partial}{\partial \theta} f_Y (\textbf{y} \mid \theta) d\textbf{y} \\
& = \frac{\partial}{\partial \theta} \int f_Y(\textbf{y} \mid \theta) d\textbf{y} \\
& = \frac{\partial}{\partial \theta} 1 \\
& = 0
\end{align*}
```
This means that

```{=tex}
\begin{align*}
    Var[X] & = E[X^2] - E[X]^2 \\
    & = E[X^2] \\
    & = E \left[ \left( \frac{\partial \log L(\theta \mid \textbf{y})}{\partial \theta} \right)^2\right ]
\end{align*}
```
and

```{=tex}
\begin{align*}
    Cov(\hat{\theta}, X) & = E[\hat{\theta} X] - E[\hat{\theta}] E[X] \\
    & = E[\hat{\theta}X] \\
    & = \int \hat{\theta} x f_Y(\textbf{y} \mid \theta) d\textbf{y} \\
    & = \int \hat{\theta} \left( \frac{\partial \log L(\theta \mid \textbf{y})}{\partial \theta} \right) f_Y(\textbf{y} \mid \theta) d\textbf{y} \\
    & = \int \hat{\theta} \left( \frac{\partial \log f_Y(\textbf{y} \mid \theta)}{\partial \theta} \right) f_Y(\textbf{y} \mid \theta) d\textbf{y} \\
    & = \int \hat{\theta} \frac{\frac{\partial}{\partial \theta} f_Y(\textbf{y} \mid \theta)}{ f_Y(\textbf{y} \mid \theta)} f_Y(\textbf{y} \mid \theta) d\textbf{y} \\
    & = \int \hat{\theta} \frac{\partial}{\partial \theta} f_Y(\textbf{y} \mid \theta) d\textbf{y}  \\
    & = \frac{\partial}{\partial \theta} \int \hat{\theta} f_Y(\textbf{y} \mid \theta) d\textbf{y}  \\
    & =  \frac{\partial}{\partial \theta} E[\hat{\theta}] \\
    & = \frac{\partial}{\partial \theta} \theta \\
    & = 1
\end{align*}
```
where $E[\hat{\theta}] = \theta$ since our estimator is unbiased. Putting this all together, we have

```{=tex}
\begin{align*}
    Var[\hat{\theta}] & \geq \frac{Cov(\hat{\theta},X)^2}{Var(X)} \\
    & = \frac{1^2}{E \left[ \left( \frac{\partial \log L(\theta \mid \textbf{y})}{\partial \theta} \right)^2\right ]} \\
    & = \frac{1}{I(\theta)}
\end{align*}
```
as desired.

**Comment:** Note that what the Cramér-Rao lower bound tells us is that, if the variance of an unbiased estimator is *equal* to the Cramér-Rao lower bound, then that estimator has the *minimum possible variance* among all unbiased estimators there could possibly be. This allows us to *prove*, for example, whether or not an unbiased estimator is the UMVUE: If an unbiased estimator's variance achieves the C-R lower bound, then it is *optimal* according to the UMVUE criterion.

## Worked Examples

**Problem 1:** Suppose $X_1, \dots, X_n \overset{iid}{\sim} Exponential(1/\theta)$. Compute the MLE of $\theta$, and show that it is an unbiased estimator of $\theta$.

**Problem 2:** Suppose again that $X_1, \dots, X_n \overset{iid}{\sim} Exponential(1/\theta)$. Let $\hat{\theta}_2 = Y_1$, and $\hat{\theta}_3 = Y_{(1)}$. Show that $\hat{\theta}_2$ and $\hat{\theta}_3$ are unbiased estimators of $\theta$. Hint: use the fact that $Y_{(1)} \sim Exponential(n/\theta)$

**Problem 3:** Compare the variance of the estimators from Problems 1 and 2. Which is most efficient?

**Problem 4:** Suppose $X_1, \dots, X_n \overset{iid}{\sim} N(\mu, \sigma^2)$. Show that the estimator $\hat{\mu} = \frac{1}{n} \sum_{i = 1}^n x_i$ *and* the estimator $\hat{\mu}_w = \sum_{i = 1}^n w_i Y_i$ are both unbiased estimators of $\mu$, where $\sum_{i = 1}^n w_i = 1$.

**Problem 5:** Determine whether the estimator $\hat{\mu}$ or $\hat{\mu}_w$ is more efficient, in Problem 5, if we additionally impose the constraint $w_i \geq 0$ $\forall i$. (Note that this is a more "general" example based on Example 5.4.5 in the course textbook)

**Problem 6:** Suppose $X_1, \dots, X_n \overset{iid}{\sim} N(\mu, \sigma^2)$. Show that the MLE for $\sigma^2$ is *biased*, and suggest a modified variance estimator for $\sigma^2$ that is *unbiased*. (Note that this is example 5.4.4 in our course textbook)
